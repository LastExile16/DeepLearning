{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'question/RNN/ChatbotSeq2Seq'\n",
      "/home/question/RNN/ChatbotSeq2Seq\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd question/RNN/ChatbotSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.Data import loadDF, tokenizer, getPairs, add_symbols, create_word_embedding, add_symbols2\n",
    "from src.Models import Seq2Seq, Encoder, Decoder\n",
    "from src.Vocab import Vocab\n",
    "from src.Train import train\n",
    "from src.Evaluate import evaluate\n",
    "from src.Chat import chat\n",
    "from src.ValEarlyStop import ValidationLossEarlyStopping\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import random, math, time\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0529c96bf0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\", \"The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\", \"The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. .\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# nltk.download('brown')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "print([\" \".join(sent) for sent in brown.sents()[0:3]])\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "\n",
    "# The default value of vector_size is 100.\n",
    "# model = gensim.models.Word2Vec(brown.sents(), size=100)\n",
    "# model.save('brown.embedding')\n",
    "\n",
    "# i can use googlenews vector which doesn't need training but it is very very large\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/question/RNN/ChatbotSeq2Seq/src/Data.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return train_df.append(validation_df)\n"
     ]
    }
   ],
   "source": [
    "data_df = loadDF('data')\n",
    "# I will take only the first 5,000 Q&A to avoid CUDA out of memory error due to the large dataset\n",
    "data_df = data_df.iloc[:5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4983</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Who was Alexander Scriabin's teacher?</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Question     Answer\n",
       "count                                    5000       5000\n",
       "unique                                   4983       3642\n",
       "top     Who was Alexander Scriabin's teacher?  Manhattan\n",
       "freq                                        2         21"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    Answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df['Question'], data_df['Qtoken'] = data_df['Question'].apply(tokenizer).str\n",
    "data_df['Answer'], data_df['Atoken'] = data_df['Answer'].apply(tokenizer).str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Qtoken</th>\n",
       "      <th>Atoken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to whom did the virgin mari alleg appear in 18...</td>\n",
       "      <td>saint bernadett soubir</td>\n",
       "      <td>[to, whom, did, the, virgin, mari, alleg, appe...</td>\n",
       "      <td>[saint, bernadett, soubir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the notr dame main build</td>\n",
       "      <td>a copper statu of christ</td>\n",
       "      <td>[what, is, in, front, of, the, notr, dame, mai...</td>\n",
       "      <td>[a, copper, statu, of, christ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the basilica of the sacr heart at notr dame is...</td>\n",
       "      <td>the main build</td>\n",
       "      <td>[the, basilica, of, the, sacr, heart, at, notr...</td>\n",
       "      <td>[the, main, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the grotto at notr dame</td>\n",
       "      <td>a marian place of prayer and reflect</td>\n",
       "      <td>[what, is, the, grotto, at, notr, dame]</td>\n",
       "      <td>[a, marian, place, of, prayer, and, reflect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what sit on top of the main build at notr dame</td>\n",
       "      <td>a golden statu of the virgin mari</td>\n",
       "      <td>[what, sit, on, top, of, the, main, build, at,...</td>\n",
       "      <td>[a, golden, statu, of, the, virgin, mari]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  to whom did the virgin mari alleg appear in 18...   \n",
       "1       what is in front of the notr dame main build   \n",
       "2  the basilica of the sacr heart at notr dame is...   \n",
       "3                    what is the grotto at notr dame   \n",
       "4     what sit on top of the main build at notr dame   \n",
       "\n",
       "                                 Answer  \\\n",
       "0                saint bernadett soubir   \n",
       "1              a copper statu of christ   \n",
       "2                        the main build   \n",
       "3  a marian place of prayer and reflect   \n",
       "4     a golden statu of the virgin mari   \n",
       "\n",
       "                                              Qtoken  \\\n",
       "0  [to, whom, did, the, virgin, mari, alleg, appe...   \n",
       "1  [what, is, in, front, of, the, notr, dame, mai...   \n",
       "2  [the, basilica, of, the, sacr, heart, at, notr...   \n",
       "3            [what, is, the, grotto, at, notr, dame]   \n",
       "4  [what, sit, on, top, of, the, main, build, at,...   \n",
       "\n",
       "                                         Atoken  \n",
       "0                    [saint, bernadett, soubir]  \n",
       "1                [a, copper, statu, of, christ]  \n",
       "2                            [the, main, build]  \n",
       "3  [a, marian, place, of, prayer, and, reflect]  \n",
       "4     [a, golden, statu, of, the, virgin, mari]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['to whom did the virgin mari alleg appear in 1858 in lourd franc',\n",
       "  'saint bernadett soubir'],\n",
       " ['what is in front of the notr dame main build', 'a copper statu of christ'],\n",
       " ['the basilica of the sacr heart at notr dame is besid to which structur',\n",
       "  'the main build'],\n",
       " ['what is the grotto at notr dame', 'a marian place of prayer and reflect'],\n",
       " ['what sit on top of the main build at notr dame',\n",
       "  'a golden statu of the virgin mari']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_sequence = getPairs(data_df)\n",
    "first_five_items = pairs_sequence[:5]\n",
    "# import itertools\n",
    "# first_five_items = list(itertools.islice(pairs_sequence, 5))\n",
    "print(len(pairs_sequence))\n",
    "first_five_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_src, max_trg = getMaxLen(pairs_sequence)\n",
    "# max_src, max_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of unique questions and answers in dataset:  8505\n",
      "raw-vocab: 6321\n",
      "vocab-length: 6324\n",
      "word2idx-length: 6324\n",
      "{0: '<pad>', 1: '<sos>', 2: '<eos>', 3: 'the', 4: 'what', 5: 'of', 6: 'in', 7: 'did', 8: 'was', 9: 'to'}\n",
      "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'the': 3, 'what': 4, 'of': 5, 'in': 6, 'did': 7, 'was': 8, 'to': 9}\n",
      "['<pad>', '<sos>', '<eos>', 'the', 'what', 'of', 'in', 'did', 'was', 'to']\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data_vocab = Vocab(data_df)\n",
    "print(\"total of unique questions and answers in dataset: \", len(data_vocab.text))\n",
    "# A_vocab = Vocab()\n",
    "\n",
    "data_vocab.build_word_vocab()\n",
    "\n",
    "print({k: data_vocab.index2word[k] for k in list(data_vocab.index2word)[:10]})\n",
    "print({k: data_vocab.word2index[k] for k in list(data_vocab.word2index)[:10]})\n",
    "print(data_vocab.word_vocab[:10])\n",
    "print(data_vocab['the'])\n",
    "print(data_vocab['oov'])\n",
    "\n",
    "# # build vocabularies for questions \"source\" and answers \"target\"\n",
    "# for pair in pairs_sequence:\n",
    "#     Q_vocab.add_words(pair[0])\n",
    "#     A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of unique questions in dataset:  4980\n",
      "raw-vocab: 4504\n",
      "vocab-length: 4507\n",
      "word2idx-length: 4507\n",
      "total of unique answers in dataset:  3525\n",
      "raw-vocab: 4081\n",
      "vocab-length: 4084\n",
      "word2idx-length: 4084\n"
     ]
    }
   ],
   "source": [
    "src_data_vocab = Vocab(data_df, source=True)\n",
    "print(\"total of unique questions in dataset: \", len(src_data_vocab.text))\n",
    "# A_vocab = Vocab()\n",
    "\n",
    "src_data_vocab.build_word_vocab()\n",
    "\n",
    "trg_data_vocab = Vocab(data_df, source=False)\n",
    "print(\"total of unique answers in dataset: \", len(trg_data_vocab.text))\n",
    "# A_vocab = Vocab()\n",
    "\n",
    "trg_data_vocab.build_word_vocab()\n",
    "\n",
    "# # build vocabularies for questions \"source\" and answers \"target\"\n",
    "# for pair in pairs_sequence:\n",
    "#     Q_vocab.add_words(pair[0])\n",
    "#     A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchdata.datapipes.iter import IterableWrapper\n",
    "# tmp = IterableWrapper(pairs_sequence).sharding_filter()\n",
    "# a, b = next(iter(tmp))\n",
    "# print(a)\n",
    "# print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source_data = [toTensor(data_vocab, pair[0]) for pair in pairs_sequence]\n",
    "# target_data = [toTensor(data_vocab, pair[1]) for pair in pairs_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(source_data[10].shape)\n",
    "# print(source_data[0].view(-1).shape)\n",
    "# print(source_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix, words_found = create_word_embedding(w2v.wv, word_vocab=src_data_vocab.word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words found in glove vocab: 1653 from 6324\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words found in glove vocab: {0} from {1}\".format(words_found, len(data_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('seq2seqEmb_vt.npy', weights_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "practice to understand batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "print(data_vocab['whom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(source_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_batches(tmp, batch_size, seq_length):\n",
    "\n",
    "#     n_batches = int(tmp.shape[0]/(batch_size*seq_length))\n",
    "#     print(n_batches)\n",
    "#     tmp = tmp[:n_batches*batch_size*seq_length]\n",
    "#     tmp = tmp.reshape(batch_size, -1)\n",
    "#     print(tmp.shape)\n",
    "#     print(tmp)\n",
    "#     print((tmp[0:2, :-1]).shape)\n",
    "#     ## now, we have to Iterate over the batches using a window of size seq_length\n",
    "#     for n in range(0, tmp.shape[1], seq_length):\n",
    "#         # The features\n",
    "#         x = tmp[:, n:n+seq_length]\n",
    "#         # The targets, shifted by one\n",
    "#         y = np.zeros_like(x)\n",
    "#         try:\n",
    "#             y[:, :-1], y[:, -1] = x[:, 1:], tmp[:, n+seq_length]\n",
    "#         except IndexError:\n",
    "#             y[:, :-1], y[:, -1] = x[:, 1:], tmp[:, 0]\n",
    "#         yield x, y\n",
    "\n",
    "# seq_length = 4\n",
    "# batch_size = 10\n",
    "# tmp = np.array([55, 20, 48, 54, 76, 36, 12,  4, 81,  7,  7,  7, 57, 48, 54, 54, 65,\n",
    "#         4, 66, 48, 69, 78,  9, 78, 36, 19,  4, 48, 12, 36,  4, 48,  9,  9,\n",
    "#         4, 48,  9, 78, 17, 36, 47,  4, 36, 27, 36, 12, 65,  4, 44, 29, 20,\n",
    "#        48, 54, 54, 65,  4, 66, 48, 69, 78,  9, 65,  4, 78, 19,  4, 44, 29,\n",
    "#        20, 48, 54, 54, 65,  4, 78, 29,  4, 78, 76, 19,  4, 18, 46, 29,  7,\n",
    "#        46, 48, 65,  0,  7,  7, 52, 27, 36, 12, 65, 76, 20, 78, 29, 213, 4])\n",
    "# i = 0\n",
    "# for d in (get_batches(tmp, batch_size, seq_length)):\n",
    "#     i +=1\n",
    "# print(f\"The number of batches (iterations): {i}\")\n",
    "# # next(get_batches(tmp, batch_size, seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# kf = KFold(n_splits=10, shuffle=True)\n",
    "# tmp = source_data[:20]\n",
    "# for e, (train_index, test_index) in enumerate(kf.split(tmp), 1):\n",
    "#     print(f\"Iteration: {e}\")\n",
    "#     print(f\"{train_index}->{len(train_index)}\")\n",
    "#     print(f\"{test_index}->{len(test_index)}\")\n",
    "\n",
    "    \n",
    "#     # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
    "\n",
    "\n",
    "def generate_batch(batch):\n",
    "    src_batch = []\n",
    "    trg_batch = []\n",
    "    src_len = []\n",
    "    i = 0\n",
    "    # print(type(batch))\n",
    "    for src, trg in batch:\n",
    "        i += 1\n",
    "        #split sentence into tokens\n",
    "        _, src_tokens = tokenizer(src)\n",
    "        # logging.warning(f'iteration {i}:\\n {src}'); # why prints 3 times while batch is 1?\n",
    "        _, trg_tokens = tokenizer(trg)\n",
    "        #convert tokens to index and to tensor and add <sos> and <eos> to each sentence\n",
    "        src_tensor = add_symbols(torch.tensor(src_data_vocab(src_tokens)).long(), src_data_vocab)\n",
    "        trg_tensor = add_symbols2(torch.tensor(trg_data_vocab(trg_tokens)).long(), trg_data_vocab)\n",
    "        src_batch.append(src_tensor)\n",
    "        #track length of each source sentence, not useful in this model. Will be useful in further models\n",
    "        src_len.append(len(src_tensor))\n",
    "        trg_batch.append(trg_tensor)\n",
    "        # logging.warning(f'iteration {i}:\\n {(src_tensor)}');\n",
    "    src_len = torch.tensor(src_len, dtype = torch.int)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=src_data_vocab['<pad>'])\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=trg_data_vocab['<pad>'])\n",
    "    src_len, idx = torch.sort(src_len,descending=True)\n",
    "    #src_len is not useful in this model\n",
    "    # logging.warning(f'lsrc_batch:{len(src_batch)}')\n",
    "    return src_batch, src_len, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(pairs_sequence, batch_size=5, collate_fn=generate_batch)\n",
    "sr, srlen, tg = (next(iter(train_dataloader)))\n",
    "print(len(srlen))\n",
    "# print(len(list(train_dataloader))) # it is grouped to 5 items per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    1,    1,    1,    1],\n",
       "        [   9,    4,    3,    4,    4],\n",
       "        [ 155,   11, 1555,   11, 1288],\n",
       "        [   7,    6,    5,    3,   22],\n",
       "        [   3, 1287,    3, 1945,  338],\n",
       "        [2666,    5, 1556,   26,    5],\n",
       "        [1942,    3, 1085,   35,    3],\n",
       "        [1943,   35,   26,   34,  242],\n",
       "        [ 234,   34,   35,    2,   88],\n",
       "        [   6,  242,   34,    0,   26],\n",
       "        [2667,   88,   11,    0,   35],\n",
       "        [   6,    2,  409,    0,   34],\n",
       "        [1944,    0,    9,    0,    2],\n",
       "        [1084,    0,   14,    0,    0],\n",
       "        [   2,    0,  549,    0,    0],\n",
       "        [   0,    0,    2,    0,    0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 483,    6,    3,    6,    6],\n",
       "        [1436,  738,  740, 1439, 1441],\n",
       "        [1437,  739,  156,  741,  739],\n",
       "        [   2,    5,    2,    5,    5],\n",
       "        [   0, 1438,    0,  742,    3],\n",
       "        [   0,    2,    0,    4,  743],\n",
       "        [   0,    0,    0, 1440,  256],\n",
       "        [   0,    0,    0,    2,    2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time/60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_DIM = len(src_data_vocab)\n",
    "OUTPUT_DIM = len(trg_data_vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.2\n",
    "DEC_DROPOUT = 0.2\n",
    "RNN_DROPOUT = 0\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, RNN_DROPOUT, weights_matrix)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, RNN_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4507, 100)\n",
       "    (rnn): LSTM(100, 32)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4084, 100)\n",
       "    (rnn): LSTM(100, 32)\n",
       "    (fc_out): Linear(in_features=32, out_features=4084, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if not name.startswith('encoder.embedding'):  # Exclude encoder embedding parameters\n",
    "            nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "            # nn.init.zeros_(param.data)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,028,176 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = optim.Adamax(model.parameters())\n",
    "\n",
    "# ignore the loss whenever the target token is a padding token.\n",
    "TRG_PAD_IDX = trg_data_vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After multiple training using the adam optimizer and batch of 12 and 10 folds\n",
    "# I have changed the batch size to 128\n",
    "# changed the optimizer to sgd\n",
    "# changed the fold to 20\n",
    "\n",
    "# finally i have changed the lr in sgd from 0.01 to 0.1 but did not train to the end. i just saved the model\n",
    "# after reloading the model, trained it for 40 epochs.\n",
    "# then changed rhe optimizer to adamax with default learning rate\n",
    "\n",
    "# model.load_state_dict(torch.load('seq2seq_adam_stemmer_brown_embedding.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 221.79it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 950.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 21s\n",
      "\tTrain Loss: 4.259 | Train PPL:  70.714\n",
      "\t Val. Loss: 4.868 |  Val. PPL: 130.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.82it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 920.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 21s\n",
      "\tTrain Loss: 3.555 | Train PPL:  34.999\n",
      "\t Val. Loss: 4.560 |  Val. PPL:  95.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.19it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 872.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 21s\n",
      "\tTrain Loss: 3.277 | Train PPL:  26.503\n",
      "\t Val. Loss: 4.629 |  Val. PPL: 102.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.72it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 947.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 21s\n",
      "\tTrain Loss: 3.154 | Train PPL:  23.438\n",
      "\t Val. Loss: 4.914 |  Val. PPL: 136.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.29it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 842.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 21s\n",
      "\tTrain Loss: 3.018 | Train PPL:  20.453\n",
      "\t Val. Loss: 5.117 |  Val. PPL: 166.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.33it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 968.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 21s\n",
      "\tTrain Loss: 2.927 | Train PPL:  18.676\n",
      "\t Val. Loss: 5.112 |  Val. PPL: 166.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.46it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 958.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 21s\n",
      "\tTrain Loss: 2.840 | Train PPL:  17.114\n",
      "\t Val. Loss: 5.163 |  Val. PPL: 174.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.51it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 943.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 21s\n",
      "\tTrain Loss: 2.763 | Train PPL:  15.846\n",
      "\t Val. Loss: 5.107 |  Val. PPL: 165.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.18it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 949.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 21s\n",
      "\tTrain Loss: 2.706 | Train PPL:  14.970\n",
      "\t Val. Loss: 5.244 |  Val. PPL: 189.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.82it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 962.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 21s\n",
      "\tTrain Loss: 2.657 | Train PPL:  14.254\n",
      "\t Val. Loss: 5.233 |  Val. PPL: 187.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.25it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 896.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 21s\n",
      "\tTrain Loss: 2.611 | Train PPL:  13.609\n",
      "\t Val. Loss: 5.083 |  Val. PPL: 161.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 223.59it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 943.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 21s\n",
      "\tTrain Loss: 2.567 | Train PPL:  13.030\n",
      "\t Val. Loss: 5.218 |  Val. PPL: 184.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.67it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 948.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 21s\n",
      "\tTrain Loss: 2.542 | Train PPL:  12.701\n",
      "\t Val. Loss: 5.056 |  Val. PPL: 157.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 226.14it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 966.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 21s\n",
      "\tTrain Loss: 2.499 | Train PPL:  12.166\n",
      "\t Val. Loss: 5.201 |  Val. PPL: 181.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.81it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 955.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 21s\n",
      "\tTrain Loss: 2.481 | Train PPL:  11.955\n",
      "\t Val. Loss: 5.136 |  Val. PPL: 170.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.04it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 957.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 21s\n",
      "\tTrain Loss: 2.448 | Train PPL:  11.569\n",
      "\t Val. Loss: 5.234 |  Val. PPL: 187.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.28it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 959.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 21s\n",
      "\tTrain Loss: 2.431 | Train PPL:  11.375\n",
      "\t Val. Loss: 5.064 |  Val. PPL: 158.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.30it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 961.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 21s\n",
      "\tTrain Loss: 2.397 | Train PPL:  10.989\n",
      "\t Val. Loss: 5.124 |  Val. PPL: 167.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 223.70it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 940.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 21s\n",
      "\tTrain Loss: 2.385 | Train PPL:  10.859\n",
      "\t Val. Loss: 4.967 |  Val. PPL: 143.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.23it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 969.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 21s\n",
      "\tTrain Loss: 2.350 | Train PPL:  10.484\n",
      "\t Val. Loss: 5.066 |  Val. PPL: 158.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 228.03it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 935.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 21s\n",
      "\tTrain Loss: 2.330 | Train PPL:  10.278\n",
      "\t Val. Loss: 5.090 |  Val. PPL: 162.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.30it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 900.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 21s\n",
      "\tTrain Loss: 2.304 | Train PPL:  10.014\n",
      "\t Val. Loss: 5.053 |  Val. PPL: 156.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.82it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 952.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 21s\n",
      "\tTrain Loss: 2.287 | Train PPL:   9.848\n",
      "\t Val. Loss: 5.186 |  Val. PPL: 178.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.97it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 947.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 21s\n",
      "\tTrain Loss: 2.261 | Train PPL:   9.592\n",
      "\t Val. Loss: 4.954 |  Val. PPL: 141.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.91it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 948.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 21s\n",
      "\tTrain Loss: 2.247 | Train PPL:   9.458\n",
      "\t Val. Loss: 4.906 |  Val. PPL: 135.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.35it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 941.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 21s\n",
      "\tTrain Loss: 2.228 | Train PPL:   9.286\n",
      "\t Val. Loss: 5.016 |  Val. PPL: 150.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.37it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 944.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 21s\n",
      "\tTrain Loss: 2.205 | Train PPL:   9.071\n",
      "\t Val. Loss: 5.137 |  Val. PPL: 170.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.51it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 957.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 21s\n",
      "\tTrain Loss: 2.192 | Train PPL:   8.949\n",
      "\t Val. Loss: 5.107 |  Val. PPL: 165.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.26it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 944.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 21s\n",
      "\tTrain Loss: 2.176 | Train PPL:   8.810\n",
      "\t Val. Loss: 5.042 |  Val. PPL: 154.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.40it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 948.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 21s\n",
      "\tTrain Loss: 2.165 | Train PPL:   8.717\n",
      "\t Val. Loss: 5.090 |  Val. PPL: 162.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.21it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 953.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Time: 0m 21s\n",
      "\tTrain Loss: 2.144 | Train PPL:   8.535\n",
      "\t Val. Loss: 5.059 |  Val. PPL: 157.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.08it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 939.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Time: 0m 21s\n",
      "\tTrain Loss: 2.131 | Train PPL:   8.423\n",
      "\t Val. Loss: 5.059 |  Val. PPL: 157.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 223.53it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 967.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Time: 0m 21s\n",
      "\tTrain Loss: 2.111 | Train PPL:   8.259\n",
      "\t Val. Loss: 4.997 |  Val. PPL: 148.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.96it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 951.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Time: 0m 21s\n",
      "\tTrain Loss: 2.092 | Train PPL:   8.101\n",
      "\t Val. Loss: 5.262 |  Val. PPL: 192.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 226.07it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 951.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Time: 0m 21s\n",
      "\tTrain Loss: 2.080 | Train PPL:   8.008\n",
      "\t Val. Loss: 5.129 |  Val. PPL: 168.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.36it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 946.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Time: 0m 21s\n",
      "\tTrain Loss: 2.073 | Train PPL:   7.946\n",
      "\t Val. Loss: 5.071 |  Val. PPL: 159.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.15it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 958.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Time: 0m 21s\n",
      "\tTrain Loss: 2.051 | Train PPL:   7.776\n",
      "\t Val. Loss: 5.048 |  Val. PPL: 155.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.43it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 936.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Time: 0m 21s\n",
      "\tTrain Loss: 2.044 | Train PPL:   7.721\n",
      "\t Val. Loss: 5.141 |  Val. PPL: 170.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.43it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 944.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Time: 0m 21s\n",
      "\tTrain Loss: 2.030 | Train PPL:   7.612\n",
      "\t Val. Loss: 5.139 |  Val. PPL: 170.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 228.18it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 949.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Time: 0m 21s\n",
      "\tTrain Loss: 2.010 | Train PPL:   7.463\n",
      "\t Val. Loss: 5.057 |  Val. PPL: 157.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.00it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 727.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 21s\n",
      "\tTrain Loss: 3.875 | Train PPL:  48.172\n",
      "\t Val. Loss: 3.927 |  Val. PPL:  50.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.18it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 958.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 21s\n",
      "\tTrain Loss: 3.331 | Train PPL:  27.964\n",
      "\t Val. Loss: 4.071 |  Val. PPL:  58.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.12it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 959.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 21s\n",
      "\tTrain Loss: 3.201 | Train PPL:  24.553\n",
      "\t Val. Loss: 4.243 |  Val. PPL:  69.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.85it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 951.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 21s\n",
      "\tTrain Loss: 3.081 | Train PPL:  21.776\n",
      "\t Val. Loss: 4.322 |  Val. PPL:  75.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.04it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 950.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 21s\n",
      "\tTrain Loss: 2.984 | Train PPL:  19.759\n",
      "\t Val. Loss: 4.358 |  Val. PPL:  78.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.21it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 859.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 21s\n",
      "\tTrain Loss: 2.906 | Train PPL:  18.286\n",
      "\t Val. Loss: 4.438 |  Val. PPL:  84.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 222.86it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 943.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 21s\n",
      "\tTrain Loss: 2.849 | Train PPL:  17.277\n",
      "\t Val. Loss: 4.565 |  Val. PPL:  96.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.04it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 952.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 21s\n",
      "\tTrain Loss: 2.801 | Train PPL:  16.459\n",
      "\t Val. Loss: 4.592 |  Val. PPL:  98.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.21it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 944.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 21s\n",
      "\tTrain Loss: 2.755 | Train PPL:  15.719\n",
      "\t Val. Loss: 4.622 |  Val. PPL: 101.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.42it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 943.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 21s\n",
      "\tTrain Loss: 2.714 | Train PPL:  15.085\n",
      "\t Val. Loss: 4.655 |  Val. PPL: 105.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.98it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 942.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 21s\n",
      "\tTrain Loss: 2.679 | Train PPL:  14.566\n",
      "\t Val. Loss: 4.769 |  Val. PPL: 117.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.33it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 934.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 21s\n",
      "\tTrain Loss: 2.633 | Train PPL:  13.915\n",
      "\t Val. Loss: 4.695 |  Val. PPL: 109.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.60it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 963.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 21s\n",
      "\tTrain Loss: 2.611 | Train PPL:  13.615\n",
      "\t Val. Loss: 4.793 |  Val. PPL: 120.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.19it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 934.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 21s\n",
      "\tTrain Loss: 2.573 | Train PPL:  13.103\n",
      "\t Val. Loss: 4.811 |  Val. PPL: 122.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.35it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 937.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 21s\n",
      "\tTrain Loss: 2.546 | Train PPL:  12.756\n",
      "\t Val. Loss: 4.904 |  Val. PPL: 134.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.86it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 938.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 21s\n",
      "\tTrain Loss: 2.521 | Train PPL:  12.445\n",
      "\t Val. Loss: 4.903 |  Val. PPL: 134.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.59it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 953.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 21s\n",
      "\tTrain Loss: 2.485 | Train PPL:  12.002\n",
      "\t Val. Loss: 4.941 |  Val. PPL: 139.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 226.59it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 963.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 21s\n",
      "\tTrain Loss: 2.457 | Train PPL:  11.673\n",
      "\t Val. Loss: 4.988 |  Val. PPL: 146.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.46it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 954.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 21s\n",
      "\tTrain Loss: 2.432 | Train PPL:  11.386\n",
      "\t Val. Loss: 4.998 |  Val. PPL: 148.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.30it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 618.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 21s\n",
      "\tTrain Loss: 2.407 | Train PPL:  11.098\n",
      "\t Val. Loss: 4.907 |  Val. PPL: 135.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 227.18it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 940.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 21s\n",
      "\tTrain Loss: 2.387 | Train PPL:  10.882\n",
      "\t Val. Loss: 4.971 |  Val. PPL: 144.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 223.55it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 947.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 21s\n",
      "\tTrain Loss: 2.362 | Train PPL:  10.617\n",
      "\t Val. Loss: 4.904 |  Val. PPL: 134.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.86it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 951.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 21s\n",
      "\tTrain Loss: 2.342 | Train PPL:  10.403\n",
      "\t Val. Loss: 5.002 |  Val. PPL: 148.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.29it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 946.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 21s\n",
      "\tTrain Loss: 2.324 | Train PPL:  10.215\n",
      "\t Val. Loss: 4.911 |  Val. PPL: 135.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 223.25it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 948.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 21s\n",
      "\tTrain Loss: 2.300 | Train PPL:   9.974\n",
      "\t Val. Loss: 4.982 |  Val. PPL: 145.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 228.88it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 964.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 21s\n",
      "\tTrain Loss: 2.272 | Train PPL:   9.697\n",
      "\t Val. Loss: 4.876 |  Val. PPL: 131.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 226.02it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 947.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 21s\n",
      "\tTrain Loss: 2.264 | Train PPL:   9.624\n",
      "\t Val. Loss: 5.003 |  Val. PPL: 148.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.46it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 948.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 21s\n",
      "\tTrain Loss: 2.245 | Train PPL:   9.443\n",
      "\t Val. Loss: 5.013 |  Val. PPL: 150.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.43it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 949.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 21s\n",
      "\tTrain Loss: 2.232 | Train PPL:   9.316\n",
      "\t Val. Loss: 5.042 |  Val. PPL: 154.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.08it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 942.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 21s\n",
      "\tTrain Loss: 2.209 | Train PPL:   9.109\n",
      "\t Val. Loss: 5.175 |  Val. PPL: 176.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.98it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 960.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Time: 0m 21s\n",
      "\tTrain Loss: 2.198 | Train PPL:   9.010\n",
      "\t Val. Loss: 5.296 |  Val. PPL: 199.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 225.50it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 957.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Time: 0m 21s\n",
      "\tTrain Loss: 2.172 | Train PPL:   8.776\n",
      "\t Val. Loss: 5.215 |  Val. PPL: 184.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 224.99it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 943.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Time: 0m 21s\n",
      "\tTrain Loss: 2.155 | Train PPL:   8.627\n",
      "\t Val. Loss: 5.229 |  Val. PPL: 186.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:20<00:00, 228.10it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 958.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Time: 0m 21s\n",
      "\tTrain Loss: 2.138 | Train PPL:   8.480\n",
      "\t Val. Loss: 5.326 |  Val. PPL: 205.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 222.10it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 950.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Time: 0m 21s\n",
      "\tTrain Loss: 2.127 | Train PPL:   8.393\n",
      "\t Val. Loss: 5.258 |  Val. PPL: 192.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4750/4750 [00:21<00:00, 216.79it/s]\n",
      "Evaluation: 100%|██████████| 250/250 [00:00<00:00, 947.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Time: 0m 22s\n",
      "\tTrain Loss: 2.111 | Train PPL:   8.254\n",
      "\t Val. Loss: 5.250 |  Val. PPL: 190.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 1841/4750 [00:08<00:13, 212.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/(Starter Code) Chatbot With LSTM and Pretrained Embeddings.ipynb Cell 38\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bevga/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/%28Starter%20Code%29%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bevga/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/%28Starter%20Code%29%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bevga/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/%28Starter%20Code%29%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     train_loss, answer_token \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, criterion, CLIP, trg_data_vocab)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bevga/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/%28Starter%20Code%29%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, val_dataloader, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bevga/home/kwchun/Workspace/udacity/nd101/lstm-homehelper-chatbot/home/question/RNN/ChatbotSeq2Seq/%28Starter%20Code%29%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m/home/question/RNN/ChatbotSeq2Seq/src/Train.py:23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, batch, optimizer, criterion, clip, data_vocab)\u001b[0m\n\u001b[1;32m     19\u001b[0m trg \u001b[39m=\u001b[39m trg\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m output \u001b[39m=\u001b[39m model(src, trg, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m \u001b[39m# trg = [trg len, batch size]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m# ouput = [trg len, batch size, output dim]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m# print(f'The output of training: {output} \\n Type is {type(output)} \\nShape is {output.shape}')\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(output)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/question/RNN/ChatbotSeq2Seq/src/Models.py:125\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    120\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(trg\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), trg\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39moutput_dim)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    122\u001b[0m \u001b[39m# encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) # 1 = number of LSTM layers\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)  \u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m encoder_hidden, cell_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(src)\n\u001b[1;32m    127\u001b[0m \u001b[39m# create sos token with target\u001b[39;00m\n\u001b[1;32m    128\u001b[0m decoder_input \u001b[39m=\u001b[39m trg[\u001b[39m0\u001b[39m, :]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/question/RNN/ChatbotSeq2Seq/src/Models.py:23\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src):\n\u001b[1;32m     21\u001b[0m     \u001b[39m# print(f'encoder src shape: {src.shape}')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m## encoder src shape: torch.Size([15, 2])\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(src))\n\u001b[1;32m     24\u001b[0m     enc_outputs, (hidden, cell_state) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(embedded)\n\u001b[1;32m     25\u001b[0m     \u001b[39m# print(f'encoder outputs shape: {enc_outputs.shape}')\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# print(f'encoder hidden shape: {hidden.shape}')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m# print(f'encoder cell_state shape: {cell_state.shape}')\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m## encoder outputs shape: torch.Size([15, 2, 1])\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m## encoder hidden shape: torch.Size([1, 2, 1])\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m## encoder cell_state shape: torch.Size([1, 2, 1])\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 40\n",
    "CLIP = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# speedup the training by reducing the size to grasp how the model is doing\n",
    "half_length = len(pairs_sequence) // 1\n",
    "cut_list = pairs_sequence[:half_length]\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "kf = KFold(n_splits=20, shuffle=True)\n",
    "\n",
    "# Lists to store performance metrics for each fold\n",
    "fold_metrics = []\n",
    "\n",
    "\n",
    "# Loop through each fold\n",
    "for fold_x, (train_indices, val_indices) in enumerate(kf.split(cut_list), 1):\n",
    "    train_data = torch.utils.data.Subset(cut_list, train_indices)\n",
    "    val_data = torch.utils.data.Subset(cut_list, val_indices)\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    \n",
    "    early_stop = ValidationLossEarlyStopping(patience=3, min_delta=0.001)\n",
    "    best_val_loss = float('inf')\n",
    "    # Training/Validation loop\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, answer_token = train(model, train_dataloader, optimizer, criterion, CLIP, trg_data_vocab)\n",
    "        val_loss = evaluate(model, val_dataloader, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'seq2seq_fold_{fold_x:02}.pt')\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')\n",
    "        \n",
    "        # if(early_stop(val_loss)):\n",
    "        #     print(f\"Repeated slow change in validation loss for {early_stop.patience} times.\")\n",
    "        #     print(f\"Early stopping at epoch {epoch+1:02} ...\")\n",
    "        #     # print(f\"The last output of the decoder: {answer_token}\")\n",
    "        #     break # let \n",
    "    fold_metrics.append(val_loss)\n",
    "    # break\n",
    "    # create new model for the next fold\n",
    "    model = Seq2Seq(enc, dec, device).to(device)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'seq2seq_adam_stemmer_brown_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 4.32\n",
      "Standard Deviation: 0.77\n",
      "All folds: [1.0730895975941963, 4.346844787485898, 4.2826411010492595, 4.712956026250031, 4.267454868079163, 4.527238293468952, 4.428322538740002, 4.939457928681746, 4.818652681002393, 4.486097786943429, 4.676842145197093, 4.4699497792646286, 4.16081991638802, 4.307067255090922, 4.1885694899829105, 4.546688701670617, 4.5680717931110415, 4.505694039381109, 4.283751132718288, 4.7336242926204575]\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and standard deviation of the accuracy across folds\n",
    "mean_accuracy = sum(fold_metrics) / len(fold_metrics)\n",
    "std_accuracy = (sum((x - mean_accuracy) ** 2 for x in fold_metrics) / len(fold_metrics)) ** 0.5\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_accuracy:.2f}\")\n",
    "print(f\"All folds: {fold_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, RNN_DROPOUT, weights_matrix)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, RNN_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "model.load_state_dict(torch.load('seq2seq_fold_01.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  what is the grotto at notre-dame?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 128, 2]\n",
      "< and colleg \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  exit\n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    src = input(\"> \")\n",
    "    if src.strip() == \"exit\":\n",
    "        break\n",
    "    chat(src, trg_data_vocab, model, 10)\n",
    "    \n",
    "# to whom did the virgin mary allegedly appear in 1858 in lourdes france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
