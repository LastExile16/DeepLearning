{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performances\n",
    "\n",
    "Now that we have seen some tricks to improve performances of a CNN, let's apply them to the CIFAR10 dataset that we used in our previous exercise. \n",
    "\n",
    "To keep things simple, we will optimize two hyperparameters.\n",
    "\n",
    "For our data augmentation, we are going to use the `RandAugment` [auto-augmentation policy](https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html) which only takes one parameter, called `magnitude`. This parameter will be one of the parameters we will optimize in our hyperparameter search.\n",
    "\n",
    "We will also optimize the learning rate for the gradient descent. \n",
    "\n",
    "When doing hyperparameter optimization, it is important to have high-level functions (or scripts) that receive our hyperparameters as inputs, so we can run as many training runs as we need by only varying the calling to the function (or the script). Of course, this would not work if we were to hard-code the parameters.\n",
    "\n",
    "Ok, enough with the introduction, let's get started!\n",
    "\n",
    "As usual, let's start by installing our requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: gitpython 3.1.32 has requirement typing-extensions>=3.7.4.3; python_version < \"3.8\", but you'll have typing-extensions 3.7.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: docker 6.1.3 has requirement requests>=2.26.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: docker 6.1.3 has requirement urllib3>=1.26.0, but you'll have urllib3 1.25.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: importlib-resources 5.12.0 has requirement zipp>=3.1.0; python_version < \"3.10\", but you'll have zipp 3.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: alembic 1.11.1 has requirement typing-extensions>=4, but you'll have typing-extensions 3.7.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: databricks-cli 0.17.7 has requirement urllib3<2.0.0,>=1.26.7, but you'll have urllib3 1.25.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlflow 1.25.1 has requirement importlib-metadata!=4.7.0,>=3.7.0, but you'll have importlib-metadata 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[33m  WARNING: The script bokeh is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts py.test and pytest are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script sqlformat is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script wsdump is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script gunicorn is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script alembic is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts databricks and dbfs are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script mlflow is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make sure that the GPU is active (otherwise things will be _very_ slow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Augmentation\n",
    "\n",
    "Here we write two functions that create appropriate transforms for the training, validation and test datasets, and then create the relative dataloaders.\n",
    "\n",
    "As usual, complete the code in the sections marked with `# YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import multiprocessing\n",
    "from helpers import get_train_val_data_loaders, get_test_data_loader\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Let's write a function that gives us the transforms so we can optimize the hyperparameters\n",
    "def get_transforms(rand_augment_magnitude):\n",
    "\n",
    "    # These are the per-channel mean and std of CIFAR-10 over the dataset\n",
    "    mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "    std = (0.24703233, 0.24348505, 0.26158768)\n",
    "\n",
    "    # Define our transformations\n",
    "    return {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                # All images in CIFAR-10 are 32x32. We enlarge them a bit so we can then\n",
    "                # take a random crop\n",
    "                T.Resize(40),\n",
    "                \n",
    "                # take a random part of the image\n",
    "                T.RandomCrop(32),\n",
    "                \n",
    "                # Horizontal flip is not part of RandAugment according to the RandAugment\n",
    "                # paper\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                \n",
    "                # Use RandAugment\n",
    "                # RandAugment has 2 main parameters: how many transformations should be\n",
    "                # applied to each image, and the strength of these transformations. This\n",
    "                # latter parameter should be tuned through experiments: the higher the more\n",
    "                # the regularization effect.\n",
    "                # Setup a T.RandAugment transformation using 2 as num_opts, and the\n",
    "                # rand_augment_magnitude input parameter as magnitude. \n",
    "                # Use T.InterpolationMode.BILINEAR as interpolation. Look at the pytorch\n",
    "                # manual if needed: \n",
    "                # https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "                \n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": T.Compose(\n",
    "            [\n",
    "                # Both of these are useless, but we keep them because\n",
    "                # in a non-academic dataset you will need them\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "            ]\n",
    "        ),\n",
    "        # Identical to the valid set in this case\n",
    "        \"test\": T.Compose(\n",
    "            [\n",
    "                T.Resize(32),\n",
    "                T.CenterCrop(32),\n",
    "                \n",
    "                # Convert to tensor and apply normalization:\n",
    "                \n",
    "                # YOUR CODE HERE\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size, valid_size, transforms, num_workers, random_seed=42):\n",
    "    \n",
    "    # Reseed random number generators to get a deterministic split. This is useful\n",
    "    # when comparing experiments, so you'll know they all run on the same data.\n",
    "    # In principle you should repeat this a few times (cross validation) to see\n",
    "    # the variability of your measurements, but we won't do this here for simplicity\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\n",
    "    # We will split this further into train and validation in this function\n",
    "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['train'])\n",
    "    valid_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['valid'])\n",
    "\n",
    "    # Compute how many items we will reserve for the validation set\n",
    "    n_tot = len(train_data)\n",
    "    split = int(np.floor(valid_size * n_tot))\n",
    "\n",
    "    # compute the indices for the training set and for the validation set\n",
    "    shuffled_indices = torch.randperm(n_tot)\n",
    "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    # NOTE that here we use train_data for the train dataloader but valid_data\n",
    "    # for the valid_loader, so the respective transforms are applied\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms['test'])\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
    "\n",
    "# specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "Here we use a model very similar to the one we used before, but we add Batch Normalization that makes our training faster and more robust, and also allows us to go deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        \n",
    "        super().__init__()\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # pooling to reduce the features\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # drop to prevent overfitting\n",
    "        self.drop2d = nn.Dropout2d(p=0.2)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        # batchnorm to train the network faster and get more accurate network\n",
    "        self.batch2dN16 = nn.BatchNorm2d(16)\n",
    "        self.batch2dN32 = nn.BatchNorm2d(32)\n",
    "        self.batch2dN64 = nn.BatchNorm2d(64)\n",
    "        self.batch2dN128 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(128*2*2, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, n_classes)\n",
    "        # batchnorm for fully connected layers\n",
    "        self.batch1dN256 = nn.BatchNorm1d(256)\n",
    "        self.batch1dN64 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.batch2dN16(self.conv1(x)))) # -> 16x16x16\n",
    "        x = self.drop2d(x)\n",
    "\n",
    "        x = F.relu(self.pool(self.batch2dN32(self.conv2(x)))) # -> 32x8x8\n",
    "        x = self.drop2d(x)\n",
    "\n",
    "        x = F.relu(self.pool(self.batch2dN64(self.conv3(x)))) # -> 64x4x4\n",
    "        x = self.drop2d(x)\n",
    "\n",
    "        x = F.relu(self.pool(self.batch2dN128(self.conv4(x)))) # -> 128x2x2\n",
    "        x = self.drop2d(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # nn.Flatten(),  # -> 1x128x2x2\n",
    "\n",
    "        x = F.relu(self.batch1dN256(self.fc1(x)))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.batch1dN64(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Learning Rate Finder\n",
    "\n",
    "Before we start our training, let's find a range for the learning rate that makes sense for our situation. We will use the learning rate finder that we've seen in one of the previous videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|█████████▊                     | 199/625 [00:18<00:38, 10.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.3028327286845545, 2.3586238531988166)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feel free to look into the code of lr_finder and see how it works!\n",
    "from lr_finder import lr_finder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64\n",
    "valid_size = 0.2\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "transforms = get_transforms(rand_augment_magnitude=9)\n",
    "data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "\n",
    "# Range  and number of steps for the learning rate\n",
    "min_lr = 1e-5\n",
    "max_lr = 1\n",
    "n_steps = min(len(data_loaders['train']), 200)\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = lr_finder(min_lr, max_lr, n_steps, loss, model, data_loaders)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(losses.keys(), losses.values())\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"learning rate (log scale)\")\n",
    "\n",
    "# Adjust the range on the y-axis to see things more clearly\n",
    "plt.xlim([1e-4, None])\n",
    "plt.ylim([min(losses.values()), np.percentile(list(losses.values()), 97)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a good initial choice for the learning rate is in the middle of the steep part. In this case it seems that 0.04 is a good initial choice.\n",
    "\n",
    "# Learning Rate Scheduler + Hyperparameter Optimization\n",
    "Let's also use two other tricks we have just learned: the learning rate scheduler, that changes the learning rate as the training progresses, and the hyperparameter optimization that optimizes the choices to maximize performance.\n",
    "\n",
    "Let's start by writing an optimize function that leverages the Learning Rate scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from helpers import train_one_epoch, valid_one_epoch\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    \n",
    "    # This is a plotting function\n",
    "    def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "        \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "        ax.set_title(group_name)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc=\"center right\")\n",
    "        \n",
    "    # initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    # Learning rate scheduler: setup a learning rate scheduler that\n",
    "    # reduces the learning rate when the validation loss reaches a\n",
    "    # plateau. Use torch.optim.lr_scheduler.ReduceLROnPlateau, with\n",
    "    # a treshold of 0.01. Look at the docs if in doubt:\n",
    "    # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', threshold=0.01, verbose=True)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            data_loaders[\"train\"], model, optimizer, loss\n",
    "        )\n",
    "\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or (\n",
    "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
    "        ):\n",
    "\n",
    "            # Save the weights to save_path\n",
    "            torch.save(model.state_dict(), save_path)  # -\n",
    "\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Update learning rate, i.e., make a step in the learning rate scheduler\n",
    "        # Remember to use the validation loss, so that the learning rate scheduler\n",
    "        # will change the learning rate when the validation loss is not \n",
    "        # decreasing anymore\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function that trains and validates our model given some hyperparameters. Let's consider for simplicity just two hyperparameters: the learning rate and the strength of the data augmentation in `RandAugment`.\n",
    "\n",
    "We are also going to track our experiments with `mlflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from helpers import one_epoch_test\n",
    "\n",
    "def train_one_model(learning_rate, rand_augment_magnitude, n_epochs):\n",
    "    \n",
    "    # TODO: the batch_size, valid_size, and num_workers are better be passed through train_one_model arguement\n",
    "    transforms = get_transforms(rand_augment_magnitude=rand_augment_magnitude)\n",
    "    data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
    "    model = Net()\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        optimize(data_loaders, model, optimizer, loss, n_epochs, \"best_val_loss.pt\", interactive_tracking=True)\n",
    "        \n",
    "        # Restore best validation loss\n",
    "        model.load_state_dict(torch.load('best_val_loss.pt'))\n",
    "        \n",
    "        # Test model on *validation* set (never optimize your hyperparameters on the \n",
    "        # test set!)\n",
    "        val_loss, preds, actuals = one_epoch_test(data_loaders['valid'], model, loss)\n",
    "        \n",
    "        # Use mlflow.log_param to log the learning rate and the\n",
    "        # rand_augment_magnitude\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"rand_augment_magnitude\", rand_augment_magnitude)\n",
    "        \n",
    "        # Use mlflow.log_metric to log your validation loss\n",
    "        # YOUR CODE HERE\n",
    "        mlflow.log_metric(\"val_loss\", val_loss)\n",
    "        \n",
    "        val_accuracy = (np.array(preds)==np.array(actuals)).sum() / len(actuals)\n",
    "        \n",
    "        # Use mlflow to log the validation accuracy as a metric\n",
    "        # YOUR CODE HERE\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        \n",
    "        # Use mlflow.log_artifact to log the best_val_loss.pt file\n",
    "        # YOUR CODE HERE\n",
    "        mlflow.log_artifact('best_val_loss.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "Let's use the random search technique to explore our hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a random grid of learning rate and rand_augment_magnitude\n",
    "\n",
    "# the following min max selected based on the result of the learning rate finder above.\n",
    "min_lr = 0.01\n",
    "max_lr = 0.1\n",
    "\n",
    "# Here you can decide how many experiments to run\n",
    "# Run between 5 and 20. The more you run the better\n",
    "# your results might be, but of course it will take\n",
    "# longer\n",
    "# Normally you would use a lot more than that, which is why\n",
    "# you typically do hyperparam optimization in the cloud so \n",
    "# all the experiments can run in parallel\n",
    "n_grid = 10 # YOUR CODE HERE\n",
    "\n",
    "# Sample log-uniformly the learning rate\n",
    "lrs = 10**(np.random.uniform(np.log10(min_lr), np.log10(max_lr), n_grid))\n",
    "# Sample uniformly the rand augment transform strength\n",
    "r_a_mag = np.random.randint(1, 15, n_grid)\n",
    "\n",
    "# Plot our grid\n",
    "_ = plt.scatter(lrs, r_a_mag)\n",
    "_ = plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/26 08:29:00 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: cannot import name 'SupportsIndex' from 'typing_extensions' (/opt/conda/lib/python3.7/site-packages/typing_extensions.py)\n",
      "Training:   1%|▎                                | 7/625 [00:00<00:48, 12.68it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 338, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to write to file </torch_1828_1149343429_2>: No space left on device (28)\n",
      "Training:   2%|▋                               | 14/625 [00:04<03:32,  2.87it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 338, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to write to file </torch_1476_74425025_5>: No space left on device (28)\n",
      "Training:   3%|▊                               | 17/625 [00:36<21:37,  2.13s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2276) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 2276) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d9c7c04b0133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run our experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_aug_mag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_a_mag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_aug_mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3a397be5c5f8>\u001b[0m in \u001b[0;36mtrain_one_model\u001b[0;34m(learning_rate, rand_augment_magnitude, n_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_val_loss.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive_tracking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Restore best validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5ec3114ccf34>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         train_loss = train_one_epoch(\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/home/helpers.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_dataloader, model, optimizer, loss)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     ):\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# move data to GPU if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2276) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Run our experiments\n",
    "for lr, rand_aug_mag in zip(lrs, r_a_mag):\n",
    "    train_one_model(lr, rand_aug_mag, n_epochs=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the results of our experiments. If you are running locally, you could now run `mlflow ui` to explore the results. If you are in the Udacity workspace, use the following code that reads the results and return them as a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['params.learning_rate', 'params.rand_augment_magnitude', 'metrics.val_loss', 'metrics.val_accuracy'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aab683db9ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"params.rand_augment_magnitude\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"metrics.val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;34m\"metrics.val_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m ].sort_values(by='metrics.val_loss')\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['params.learning_rate', 'params.rand_augment_magnitude', 'metrics.val_loss', 'metrics.val_accuracy'] not in index\""
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "runs = mlflow.search_runs()\n",
    "sorted_runs = runs[\n",
    "    [\n",
    "        \"run_id\",\n",
    "        \"params.learning_rate\",\n",
    "        \"params.rand_augment_magnitude\",\n",
    "        \"metrics.val_loss\",\n",
    "        \"metrics.val_accuracy\",\n",
    "    ]\n",
    "].sort_values(by='metrics.val_loss')\n",
    "sorted_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7da3a80fe1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the id with the lowest val_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlowest_loss_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_runs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fetch the best model from that run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_runs' is not defined"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Get the id with the lowest val_loss\n",
    "lowest_loss_id = sorted_runs.iloc[0]['run_id']\n",
    "\n",
    "# Fetch the best model from that run\n",
    "client = MlflowClient()\n",
    "local_path = client.download_artifacts(lowest_loss_id, \"best_val_loss.pt\", '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_val_loss.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data! A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import one_epoch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy: 77% (7701/10000)\n",
    "\n",
    "test_loss, preds, actuals = one_epoch_test(data_loaders['test'], model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import plot_confusion_matrix\n",
    "\n",
    "cm = plot_confusion_matrix(preds, actuals, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved on our previous results by almost 5%. There is a lot more that can be done, feel free to keep experimenting with different augmentations for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
